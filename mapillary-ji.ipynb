{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/izabelljaro/mapillary-ji?scriptVersionId=157426629\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Mapillary dataset\n\n### new labeling, data augmentation\n\nSource of image augmentation:\nhttps://imgaug.readthedocs.io/en/latest/index.html","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport imgaug.augmenters as iaa\nimport cv2\nimport matplotlib.pyplot as plt\nfrom imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Filter dataset: prohibitory signs","metadata":{}},{"cell_type":"code","source":"# Read labels grouped by object\ngrouped_by_object = pd.read_csv(\"dataset_object_by_object.csv\",sep=\",\", index_col=0)\ngrouped_by_object","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_of_all_images = grouped_by_object['name'].value_counts()\nnumber_of_all_images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Needed classes\nclass_ids = [\n    'no-right-left-or-u-turn',\n    'speed-limit',\n    'road-closed',\n    'no-entry',\n    'no-stopping-no-parking',\n    'other'\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categories to rename\nclass_renames = {'regulatory--height-limit--g1': 'other',\n                 'regulatory--maximum-speed-limit-5--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-10--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-15--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-20--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-25--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-30--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-40--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-45--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-50--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-60--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-70--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-80--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-90--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-100--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-110--g1': 'speed-limit',\n                 'regulatory--maximum-speed-limit-120--g1': 'speed-limit',\n                 'regulatory--minimum-safe-distance--g1': 'other',\n                 'regulatory--no-bicycles--g1': 'other',\n                 'regulatory--no-entry--g1': 'no-entry',\n                 'regulatory--no-heavy-goods-vehicles--g1': 'other',\n                 'regulatory--no-left-turn--g1': 'no-right-left-or-u-turn',\n                 'regulatory--no-left-turn--g2': 'no-right-left-or-u-turn',\n                 'regulatory--no-left-turn--g3': 'no-right-left-or-u-turn',\n                 'regulatory--no-motorcycles--g1': 'other',\n                 'regulatory--no-motorcycles--g2': 'other',\n                 'regulatory--no-motor-vehicles-except-motorcycles--g1': 'other',\n                 'regulatory--no-motor-vehicles-except-motorcycles--g2': 'other',\n                 'regulatory--no-overtaking-by-heavy-goods-vehicles--g1': 'other',\n                 'regulatory--no-overtaking--g1': 'other',\n                 'regulatory--no-parking--g1': 'no-stopping-no-parking',\n                 'regulatory--no-right-turn--g1': 'no-right-left-or-u-turn',\n                 'regulatory--no-right-turn--g2': 'no-right-left-or-u-turn',\n                 'regulatory--no-right-turn--g3': 'no-right-left-or-u-turn',\n                 'regulatory--no-stopping--g15': 'no-stopping-no-parking',\n                 'regulatory--no-u-turn--g1': 'no-right-left-or-u-turn',\n                 'regulatory--no-u-turn--g2': 'no-right-left-or-u-turn',\n                 'regulatory--no-u-turn--g3': 'no-right-left-or-u-turn',\n                 'regulatory--road-closed-to-vehicles--g3': 'road-closed',\n                 'regulatory--weight-limit--g1': 'other',\n                 'regulatory--width-limit--g1': 'other'\n                }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename categories\ngrouped_by_object['class'] = grouped_by_object['class'].replace(class_renames)\ngrouped_by_object","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dataframe conntaining only the needed classes\nfiltered_obj = grouped_by_object[grouped_by_object['class'].isin(class_ids)]\nfiltered_obj","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset grouped by image\ngrouped_df = filtered_obj.groupby(['name']).agg({col:lambda x: list(x) for col in filtered_obj.columns[1:]}).reset_index()\ngrouped_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save dataframe\n#grouped_df.to_csv(\"grouped_by_image_new_classes.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# delete the unnecessary files\n\nimage_names_to_keep = grouped_df['name'].tolist() # list of image filenames\n\nfolder_paths = ['./train_0/reduced', './train_1/reduced', './train_2/reduced', './val/reduced']\n\nnum_deleted_images = 0\nfor folder_path in folder_paths:\n    \n    all_files = os.listdir(folder_path)\n    files_to_delete = [file for file in all_files if os.path.splitext(file)[0] not in image_names_to_keep]\n\n    \n    for file_to_delete in files_to_delete:\n        file_path = os.path.join(folder_path, file_to_delete)\n        \n        os.remove(file_path)\n        num_deleted_images +=1\n        \n        #print(f\"Deleted: {file_path}\")\n        \nprint('Number of deleted images: ', num_deleted_images)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution of the classes (all filtered data)\n\nnumber_of_classes = filtered_obj['class'].value_counts()\nnumber_of_classes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train test val split","metadata":{}},{"cell_type":"code","source":"# calculation og the number of each set\n\ntrain_ratio = 0.7\ntest_ratio = 0.2\n\nnum_train = int(len(grouped_df) * train_ratio)\nnum_test = int(len(grouped_df) * test_ratio)\nnum_val = len(grouped_df) - num_train - num_test\n\nprint('number of train images: ',num_train,'\\nnumber of test images: ',num_test,'\\nnumber of validation images: ',num_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = grouped_df['name']\nnp.random.seed(12)\nnp.random.shuffle(filenames)\n\ntrain_set = filenames[:num_train]\ntest_set = filenames[num_train:num_train + num_test]\nval_set =filenames[-num_val:]\n\n#with open('train.txt', 'w') as f_train:\n#    f_train.write('\\n'.join(train_set))\n\n#with open('test.txt', 'w') as f_test:\n#    f_test.write('\\n'.join(test_set))\n\n#with open('validation.txt', 'w') as f_val:\n#    f_val.write('\\n'.join(val_set))","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set\nwith open('./mapillary_JI/new_test_train_val_split/train.txt', 'r') as f_train:\n    train_set = f_train.read().splitlines()\n    \ntrain_set","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filtered_obj_train: train set grouped by objects\n# filtered_obj: grouped by object, filtered\n# grouped_df: grouped by image, filtered\n\nfiltered_obj_train = filtered_obj[filtered_obj['name'].isin(train_set)]\nnum_of_classes_train = filtered_obj_train['class'].value_counts()\nnum_of_classes_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data augmentation should be done on the train set, and the final number of images of the classes should match the number of elements of the largest class (speed limit ~3600)","metadata":{}},{"cell_type":"code","source":"filtered_obj_train\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped_df_train = grouped_df = filtered_obj_train.groupby(['name']).agg({col:lambda x: list(x) for col in filtered_obj_train.columns[1:]}).reset_index()\ngrouped_df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data augmentation","metadata":{}},{"cell_type":"code","source":"# Define the augmentation sequence\n\naugmentation = iaa.Sequential([\n    iaa.Fliplr(0.4),  # Horizontal flip with a 40% probability\n    \n    # Affine transformations\n    iaa.Affine(\n        rotate=(-10, 10),\n        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n        shear=(-10, 10)\n    ),\n    # Gaussian blur with random sigma between 0 and 1.\n    # But we only blur about 50% of all images.\n    iaa.Sometimes(\n        0.5,\n        iaa.GaussianBlur(sigma=(0, 1))\n    ),\n    # Sharpen with 50% probability\n    iaa.Sometimes(\n        0.5,\n        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5))\n    ),\n    # change brightness, doesn't affect BBs\n    iaa.Multiply((1.2, 1.5)),\n    \n    # Strengthen or weaken the contrast in each image.\n    iaa.LinearContrast((0.75, 1.5))\n    \n    ])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Data augmentation on 5 example images","metadata":{}},{"cell_type":"code","source":"# Apply augmentation to the first 5 rows (example images)\n\nfor index, row in filtered_obj.head(5).iterrows():\n    \n    image_path = f\"./mapillary_JI/example_images/{row['name']}.jpg\"\n    image = cv2.imread(image_path)\n    \n    # Extract bounding box coordinates\n    bbs = BoundingBoxesOnImage([\n        BoundingBox(x1=row['xmin'], y1=row['ymin'], x2=row['xmax'], y2=row['ymax'])\n    ], shape=image.shape)\n    \n    # Apply augmentation\n    augmented_image, augmented_bboxes = augmentation(image=image, bounding_boxes=bbs)\n    \n    # Print bounding boxes\n    print(\"Bounding box change: (%.4f, %.4f, %.4f, %.4f) -> (%.4f, %.4f, %.4f, %.4f)\" % (\n        bbs.bounding_boxes[0].x1, bbs.bounding_boxes[0].y1, bbs.bounding_boxes[0].x2, bbs.bounding_boxes[0].y2,\n        augmented_bboxes.bounding_boxes[0].x1, augmented_bboxes.bounding_boxes[0].y1, augmented_bboxes.bounding_boxes[0].x2, augmented_bboxes.bounding_boxes[0].y2)\n    )\n    \n    # image with BBs before/after augmentation\n    image_before = bbs.draw_on_image(image, size=2)\n    image_after = augmented_bboxes.draw_on_image(augmented_image, size=2, color=[0, 0, 255])\n\n    # Visualize the original and augmented images with bounding boxes\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.imshow(cv2.cvtColor(image_before, cv2.COLOR_BGR2RGB))\n    plt.title('Original Image with Bounding Box')\n    plt.subplot(1, 2, 2)\n    plt.imshow(cv2.cvtColor(image_after, cv2.COLOR_BGR2RGB))\n    plt.title('Augmented Image with Adjusted Bounding Box')\n    plt.show()\n    \n","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hard to spot te bounding box, because of its small size, but in these examples the boxes transformed well.","metadata":{}},{"cell_type":"markdown","source":"### Data augmentation of the train set","metadata":{}},{"cell_type":"code","source":"# Creating one folder from old 4\n\nsource_folder1 = './train_0/reduced'\nsource_folder2 = './train_1/reduced'\nsource_folder3 = './train_2/reduced'\nsource_folder4 = './val/reduced'\ndestination_folder = './all_images'\n\nos.makedirs(destination_folder, exist_ok=True)\n\n# Function to move the contents of a source folder to the destination folder\ndef move_contents(source_folder, destination_folder):\n    for item in os.listdir(source_folder):\n        source_item_path = os.path.join(source_folder, item)\n        destination_item_path = os.path.join(destination_folder, item)\n\n        if os.path.isdir(source_item_path):\n            os.makedirs(destination_item_path, exist_ok=True)\n            move_contents(source_item_path, destination_item_path)\n            os.rmdir(source_item_path)\n        else:\n            \n            os.rename(source_item_path, destination_item_path)\n\nmove_contents(source_folder1, destination_folder)\nmove_contents(source_folder2, destination_folder)\nmove_contents(source_folder3, destination_folder)\nmove_contents(source_folder4, destination_folder)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = filtered_obj_train\nimages_dir = './all_images'\n\noutput_dir = './augmented_images_train'\nos.makedirs(output_dir, exist_ok=True)\n\nclass_counts = df['class'].value_counts()\n\ntarget_objects_per_class = class_counts.max()\nprint('Target object per class: ',target_objects_per_class)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New DataFrame to store augmented images\naugmented_df = pd.DataFrame(columns=df.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For now: only for one class (road-closed) to test\nfor class_name, count in class_counts.items(): # this is for all classes\n#class_name='road-closed'\n#count = 204\n    if class_name != 'road-closed':\n        print('class_name: ', class_name )\n\n        # choosing one class\n        class_subset = df[df['class'] == class_name]\n\n        # oversampling factor\n        oversampling_factor = (target_objects_per_class // count )+1\n        class_subset_oversampled = pd.concat([class_subset] * oversampling_factor, ignore_index=True)\n\n        # subset selection\n        #print(subset_size)\n        subset_size = min(target_objects_per_class, len(class_subset_oversampled))\n        class_subset_selected = class_subset_oversampled.sample(subset_size, random_state=42)\n\n        # image augmentation\n        for index, row in class_subset_selected.iterrows():\n            original_image_path = f\"{images_dir}/{row['name']}.jpg\"\n            #if index == 471:\n            if True:\n\n                original_image = cv2.imread(original_image_path)\n\n\n                # Extract bounding box coordinates\n                boundingboxes = BoundingBoxesOnImage([\n                    BoundingBox(x1=row['xmin'], y1=row['ymin'], x2=row['xmax'], y2=row['ymax'])\n                ], shape=original_image.shape)  \n\n                #print(boundingboxes)\n\n                # Apply augmentation\n                augmented_image, augmented_bboxes = augmentation(image=original_image,bounding_boxes=boundingboxes)\n                augmented_bboxes=augmented_bboxes.bounding_boxes[0]\n                #print(augmented_bboxes)\n                #plt.figure()\n                #plt.imshow(cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB))\n\n\n                augmented_image_name = f\"{os.path.splitext(row['name'])[0]}_{index}_aug.jpg\"\n                augmented_image_path = os.path.join(output_dir, augmented_image_name)\n                #print(augmented_image_path)\n\n                cv2.imwrite(augmented_image_path, augmented_image)\n\n\n                augmented_row = pd.DataFrame([{\n                    'name': f\"{os.path.splitext(row['name'])[0]}_{index}_aug\",\n                    'width': row['width'],  \n                    'height': row['height'],  \n                    'class': row['class'],  \n                    'xmin': augmented_bboxes.x1,\n                    'ymin': augmented_bboxes.y1,\n                    'xmax': augmented_bboxes.x2,\n                    'ymax': augmented_bboxes.y2,\n                }])\n\n\n                augmented_df = pd.concat([augmented_df, augmented_row], ignore_index=True)\n\n            \n        \naugmented_df\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I accidentally augmented for the biggest class, so I need to delete those augmented images\n# because they are not necessary\naug_img_to_delete = augmented_df[augmented_df['class'] == 'speed-limit']['name']\n\n#output_dir: aug_images_train\n\nfor img_name in aug_img_to_delete:\n    path = f\"{output_dir}/{img_name}.jpg\"\n    os.remove(path)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now I delete the rows from the dataset\naugmented_df = augmented_df[augmented_df['class'] != 'speed-limit']\naugmented_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save dataframe\naugmented_df.to_csv(\"./mapillary_JI/grouped_by_object_augmented_otherall.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization of augmented images\n\n#_CkxBP6-SGo-ZYsPhVUa8w.jpg\nimage_path = r'./all_images/_CkxBP6-SGo-ZYsPhVUa8w.jpg'\nog = cv2.imread(image_path)\nplt.imshow(cv2.cvtColor(og, cv2.COLOR_BGR2RGB))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = [filename for filename in os.listdir('./augmented_images_train') if 'CkxBP6-SGo-ZYsPhVUa8w' in filename]\n#filenames","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=10, ncols=2,figsize=(10,80))\naxes = axes.flatten()\nfor i, image_filename in enumerate(filenames):\n    \n    img_path = os.path.join('./augmented_images_train', image_filename)\n    img = cv2.imread(img_path)\n    \n    axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    axes[i].axis('off')\n\naxes[i+1].axis('off')\n#plt.tight_layout()\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I did the data augmentation in two parts. I read the two saved dataframe, and make one\ndf1 = pd.read_csv(\"./mapillary_JI/grouped_by_object_augmented_road_closed.csv\",sep=\",\", index_col=0)\ndf2 = pd.read_csv(\"./mapillary_JI/grouped_by_object_augmented_otherall.csv\",sep=\",\", index_col=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_obj","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concatenating them\nobject_aug = pd.concat([df1, df2], ignore_index=True)\nobject_aug.to_csv(\"./mapillary_JI/object_aug.csv\")\nobject_all = pd.concat([object_aug, filtered_obj], ignore_index=True)\nobject_all.to_csv(\"./mapillary_JI/object_all.csv\")\n\nobject_all","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset grouped by image (one aug image should contain only one object)\nimage_aug = object_aug.groupby(['name']).agg({col:lambda x: list(x) for col in object_aug.columns[1:]}).reset_index()\nimage_all = object_all.groupby(['name']).agg({col:lambda x: list(x) for col in object_all.columns[1:]}).reset_index()\n\nimage_aug.to_csv(\"./mapillary_JI/image_aug.csv\")\nimage_all.to_csv(\"./mapillary_JI/image_all.csv\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_aug","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_all","metadata":{},"execution_count":null,"outputs":[]}]}