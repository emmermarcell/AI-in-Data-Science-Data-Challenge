{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data challenge\n\nYour task is to build an algorithm for prohibitory traffic sign recognition. We have\ncreated a training data set (20 images) that can be used for building and fine-tuning a model.\nHowever, you are encouraged to collect more images, since it will allow you to improve your\nmodelâ€™s performance.\n\nThere are 6 traffic sign categories your model should be able to recognize:\n* Category A - no right, left, or U-turn\n* Category B - speed limit (regardless of the indicated value)\n* Category C - road closed\n* Category D - no entry\n* Category E - no stopping, no parking\n* Category F - other types of prohibitory traffic signs\n\n## Not I'll try to implement the [YOLOv8][1] in KerasCV, an extension of Keras for computer vision\n\nSince pytorch is still a bit new to me and the origninal docs kind of forced me to upload our traffic to the roboflow website where they augmented the data without any code. I felt like that ruined the purpose of the data challenge. So now I'll follow this tutorial:\n\nhttps://keras.io/examples/vision/yolov8/\n\n[1]: https://keras.io/api/keras_cv/models/backbones/yolo_v8/\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install kerascv","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:29:07.794628Z","iopub.execute_input":"2023-12-17T15:29:07.795323Z","iopub.status.idle":"2023-12-17T15:29:19.776126Z","shell.execute_reply.started":"2023-12-17T15:29:07.795280Z","shell.execute_reply":"2023-12-17T15:29:19.774907Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Requirement already satisfied: kerascv in /opt/conda/lib/python3.10/site-packages (0.0.40)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from kerascv) (3.9.0)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from h5py->kerascv) (1.24.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import packages\nimport os\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport keras_cv\nfrom keras_cv import bounding_box\nfrom keras_cv import visualization\n\n# Define hyperparameters\nSPLIT_RATIO = 0.5\nBATCH_SIZE = 4\nLEARNING_RATE = 0.001\nEPOCH = 5\nGLOBAL_CLIPNORM = 10.0","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:29:19.778617Z","iopub.execute_input":"2023-12-17T15:29:19.778998Z","iopub.status.idle":"2023-12-17T15:29:19.785633Z","shell.execute_reply.started":"2023-12-17T15:29:19.778964Z","shell.execute_reply":"2023-12-17T15:29:19.784535Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"# Load in the Traffic Sign Data","metadata":{}},{"cell_type":"code","source":"class_ids = [\n    'no-right-left-or-u-turn',\n    'speed-limit',\n    'road-closed',\n    'no-entry',\n    'no-stopping-no-parking',\n    'other'\n]\n\nclass_mapping = {class_name: class_id for class_id, class_name in enumerate(class_ids)}\nprint(class_mapping)\n\n# Path to images\npath_images = '/kaggle/input/traffic-signs-data-challenge/train'\n\n# Get all JPEG image file paths in path_images and sort them\njpg_files = sorted(\n    [\n        os.path.join(path_images, file_name)\n        for file_name in os.listdir(path_images)\n        if file_name.endswith(\".jpg\")\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:29:19.787047Z","iopub.execute_input":"2023-12-17T15:29:19.787383Z","iopub.status.idle":"2023-12-17T15:29:19.804660Z","shell.execute_reply.started":"2023-12-17T15:29:19.787354Z","shell.execute_reply":"2023-12-17T15:29:19.803851Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"{'no-right-left-or-u-turn': 0, 'speed-limit': 1, 'road-closed': 2, 'no-entry': 3, 'no-stopping-no-parking': 4, 'other': 5}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read the annotation file inot a pandas dataframe\nannot_file = '/kaggle/input/traffic-signs-data-challenge/train/_annotations.csv'\nannot_df = pd.read_csv(annot_file)\n\nannot_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:29:19.806668Z","iopub.execute_input":"2023-12-17T15:29:19.806997Z","iopub.status.idle":"2023-12-17T15:29:19.829269Z","shell.execute_reply.started":"2023-12-17T15:29:19.806970Z","shell.execute_reply":"2023-12-17T15:29:19.827955Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"                                         filename  width  height  \\\n0  17_jpg.rf.06cf807529216c05e2421a97e9a3c9aa.jpg    600     300   \n1  17_jpg.rf.06cf807529216c05e2421a97e9a3c9aa.jpg    600     300   \n2  17_jpg.rf.06cf807529216c05e2421a97e9a3c9aa.jpg    600     300   \n3   6_jpg.rf.8249332fe6bb156f9730dd96d112223f.jpg    600     300   \n4   6_jpg.rf.8249332fe6bb156f9730dd96d112223f.jpg    600     300   \n\n                    class  xmin  ymin  xmax  ymax  \n0                no-entry    22   149    60   177  \n1  no-stopping-no-parking   520   160   570   198  \n2                   other   522   236   571   274  \n3             road-closed   506   121   542   153  \n4                   other   555    97   597   131  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17_jpg.rf.06cf807529216c05e2421a97e9a3c9aa.jpg</td>\n      <td>600</td>\n      <td>300</td>\n      <td>no-entry</td>\n      <td>22</td>\n      <td>149</td>\n      <td>60</td>\n      <td>177</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17_jpg.rf.06cf807529216c05e2421a97e9a3c9aa.jpg</td>\n      <td>600</td>\n      <td>300</td>\n      <td>no-stopping-no-parking</td>\n      <td>520</td>\n      <td>160</td>\n      <td>570</td>\n      <td>198</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17_jpg.rf.06cf807529216c05e2421a97e9a3c9aa.jpg</td>\n      <td>600</td>\n      <td>300</td>\n      <td>other</td>\n      <td>522</td>\n      <td>236</td>\n      <td>571</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6_jpg.rf.8249332fe6bb156f9730dd96d112223f.jpg</td>\n      <td>600</td>\n      <td>300</td>\n      <td>road-closed</td>\n      <td>506</td>\n      <td>121</td>\n      <td>542</td>\n      <td>153</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6_jpg.rf.8249332fe6bb156f9730dd96d112223f.jpg</td>\n      <td>600</td>\n      <td>300</td>\n      <td>other</td>\n      <td>555</td>\n      <td>97</td>\n      <td>597</td>\n      <td>131</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"grouped_df = annot_df.groupby(['filename']).agg({col:lambda x: list(x) for col in annot_df.columns[1:]}).reset_index()\n\ngrouped_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:29:19.832097Z","iopub.execute_input":"2023-12-17T15:29:19.832681Z","iopub.status.idle":"2023-12-17T15:29:19.866932Z","shell.execute_reply.started":"2023-12-17T15:29:19.832648Z","shell.execute_reply":"2023-12-17T15:29:19.866100Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"                                         filename            width  \\\n0  10_jpg.rf.73da5bf11a250d18d212bd276be2a02e.jpg  [600, 600, 600]   \n1  11_jpg.rf.788b737ab908f716125157158a741b1d.jpg       [600, 600]   \n2  12_jpg.rf.f2fd7c2e462831e1225e480312289ad9.jpg       [600, 600]   \n3  13_jpg.rf.d5301f84fec055b793adabfb5e4ef329.jpg  [600, 600, 600]   \n4  14_jpg.rf.b69dd2f82bdc031b0ccd416aaa8ffaf5.jpg  [600, 600, 600]   \n\n            height                                              class  \\\n0  [300, 300, 300]  [road-closed, no-stopping-no-parking, speed-li...   \n1       [300, 300]                 [no-stopping-no-parking, no-entry]   \n2       [300, 300]              [speed-limit, no-stopping-no-parking]   \n3  [300, 300, 300]       [speed-limit, other, no-stopping-no-parking]   \n4  [300, 300, 300]                        [other, other, speed-limit]   \n\n              xmin             ymin             xmax             ymax  \n0  [211, 515, 515]   [175, 107, 68]  [240, 557, 555]  [203, 143, 104]  \n1         [543, 6]        [67, 112]        [600, 42]       [142, 146]  \n2       [521, 524]       [147, 186]       [556, 556]       [177, 214]  \n3  [431, 432, 430]   [149, 120, 91]  [459, 460, 460]  [176, 149, 120]  \n4  [463, 456, 319]  [104, 158, 124]  [487, 496, 327]  [158, 213, 134]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10_jpg.rf.73da5bf11a250d18d212bd276be2a02e.jpg</td>\n      <td>[600, 600, 600]</td>\n      <td>[300, 300, 300]</td>\n      <td>[road-closed, no-stopping-no-parking, speed-li...</td>\n      <td>[211, 515, 515]</td>\n      <td>[175, 107, 68]</td>\n      <td>[240, 557, 555]</td>\n      <td>[203, 143, 104]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11_jpg.rf.788b737ab908f716125157158a741b1d.jpg</td>\n      <td>[600, 600]</td>\n      <td>[300, 300]</td>\n      <td>[no-stopping-no-parking, no-entry]</td>\n      <td>[543, 6]</td>\n      <td>[67, 112]</td>\n      <td>[600, 42]</td>\n      <td>[142, 146]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12_jpg.rf.f2fd7c2e462831e1225e480312289ad9.jpg</td>\n      <td>[600, 600]</td>\n      <td>[300, 300]</td>\n      <td>[speed-limit, no-stopping-no-parking]</td>\n      <td>[521, 524]</td>\n      <td>[147, 186]</td>\n      <td>[556, 556]</td>\n      <td>[177, 214]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13_jpg.rf.d5301f84fec055b793adabfb5e4ef329.jpg</td>\n      <td>[600, 600, 600]</td>\n      <td>[300, 300, 300]</td>\n      <td>[speed-limit, other, no-stopping-no-parking]</td>\n      <td>[431, 432, 430]</td>\n      <td>[149, 120, 91]</td>\n      <td>[459, 460, 460]</td>\n      <td>[176, 149, 120]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14_jpg.rf.b69dd2f82bdc031b0ccd416aaa8ffaf5.jpg</td>\n      <td>[600, 600, 600]</td>\n      <td>[300, 300, 300]</td>\n      <td>[other, other, speed-limit]</td>\n      <td>[463, 456, 319]</td>\n      <td>[104, 158, 124]</td>\n      <td>[487, 496, 327]</td>\n      <td>[158, 213, 134]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize lists to store information\nimage_paths = []\nbbox = []\nclasses = []\n\n\ndef parse_annotation_csv(row):\n    # Get the path pf the image\n    image_name = row['filename']\n    image_path = os.path.join(path_images, image_name)\n    \n    # Get the bounding box of the traffic sign\n    boxes = [row['xmin'], row['ymin'], row['xmax'], row['ymax']]\n    \n    # Get the class id of the traffic sign\n    class_ids = row['class']\n    \n    return image_path, boxes, class_ids\n\n# Process annotations for each row in the DataFrame\nfor index, row in grouped_df.iterrows():\n    image_path, boxes, class_ids = parse_annotation_csv(row)\n    \n    image_paths.append(image_path)\n    bbox.append(boxes)\n    classes.append(class_ids)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:29:19.867990Z","iopub.execute_input":"2023-12-17T15:29:19.868515Z","iopub.status.idle":"2023-12-17T15:29:19.878728Z","shell.execute_reply.started":"2023-12-17T15:29:19.868487Z","shell.execute_reply":"2023-12-17T15:29:19.877278Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"Ragged tensors are used to create a tf.data.Dataset using the from_tensor_slices method. This method creates a dataset from the input tensors by slicing them along the first dimension. By using ragged tensors, the dataset can handle varying lengths of data for each image and provide a flexible input pipeline for further processing.","metadata":{}},{"cell_type":"code","source":"bbox = tf.ragged.constant(bbox)\nclasses = tf.ragged.constant(classes)\nimage_paths = tf.ragged.constant(image_paths)\n\ndata = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:29:19.879897Z","iopub.execute_input":"2023-12-17T15:29:19.880219Z","iopub.status.idle":"2023-12-17T15:29:19.893653Z","shell.execute_reply.started":"2023-12-17T15:29:19.880186Z","shell.execute_reply":"2023-12-17T15:29:19.892498Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## Train Validation split","metadata":{}},{"cell_type":"code","source":"# Determine the number of validation samples\nnum_val = int(len(grouped_df) * SPLIT_RATIO)\n\n# Split the dataset into train and validation sets\nval_data = data.take(num_val)\ntrain_data = data.skip(num_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:29:19.895109Z","iopub.execute_input":"2023-12-17T15:29:19.895623Z","iopub.status.idle":"2023-12-17T15:29:19.921683Z","shell.execute_reply.started":"2023-12-17T15:29:19.895586Z","shell.execute_reply":"2023-12-17T15:29:19.920760Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}